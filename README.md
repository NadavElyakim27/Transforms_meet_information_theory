# Introduction
Training a pre-trained BERT transformer model on a corpus of Harry Potter books to generate paragraphs and examining elements of information theory on the model's results.
The work can be found in the [notebook](https://github.com/NadavElyakim27/Transforms-meet-information-theory/blob/ae3fe9cbaad464e3b7d0e871d776c7fa6518914b/Transforms_meet_information_theory.ipynb) 

## Thanks for visiting
