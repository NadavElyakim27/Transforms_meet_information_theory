# Introduction
Training a pre-trained BERT transformer model on a corpus of Harry Potter books to generate paragraphs and examining elements of information theory on the model's results.
The work can be found in the [notebook](https://github.com/NadavElyakim27/Transforms-meet-information-theory/blob/ae3fe9cbaad464e3b7d0e871d776c7fa6518914b/Transforms_meet_information_theory.ipynb) 

## Thanks for visiting
![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2FNadavElyakim27%2FTransforms_meet_information_theory.git&labelColor=%232ccce4&countColor=%23555555&style=flat)
